{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89a1d53-4314-4f79-8852-f261480192ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import time\n",
    "import logging\n",
    "\n",
    "## Feature-scaling stack\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "## Dimesionality reduction\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "## Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "## Machine-learning stack\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, AdaBoostClassifier \n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "## Metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, roc_curve, roc_auc_score, auc, fbeta_score, f1_score\n",
    "\n",
    "## Model saving\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e885ba1-971f-46a4-84ce-7ed1df1d992b",
   "metadata": {},
   "source": [
    "# Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff174bee-4ed4-41d5-8f83-19a64a529a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE = {\n",
    "    'rf':     {'cross-val':    0,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "    'xgb':    {'cross-val':    0,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "    'lgb':    {'cross-val':    0,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "    'cb':     {'cross-val':    0,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "    'ada':    {'cross-val':    1,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "    'svc':    {'cross-val':    1,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "    'soft-v': {'cross-val':    1,\n",
    "               'compute-pauc': 1,\n",
    "               'final-train':  1,\n",
    "               'save-model':   1,\n",
    "              },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9e7df-b69a-4a8f-ab7a-8ba123f13735",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04d18c79-052b-4c86-a5b6-d4794914e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_auc_score(y_actual, y_scores, tpr_threshold=0.80):\n",
    "    max_fpr = 1 - tpr_threshold\n",
    "\n",
    "    # create numpy arrays\n",
    "    y_actual = np.asarray(y_actual)\n",
    "    y_scores = np.asarray(y_scores)\n",
    "\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_actual, y_scores)\n",
    "\n",
    "    # Find the index where fpr exceeds max_fpr\n",
    "    stop_index = np.searchsorted(fpr, max_fpr, side='right')\n",
    "\n",
    "    if stop_index < len(fpr):\n",
    "        # Interpolate to find the TPR at max_fpr\n",
    "        fpr_interp_points = [fpr[stop_index - 1], fpr[stop_index]]\n",
    "        tpr_interp_points = [tpr[stop_index - 1], tpr[stop_index]]\n",
    "        tpr = np.append(tpr[:stop_index], np.interp(max_fpr, fpr_interp_points, tpr_interp_points))\n",
    "        fpr = np.append(fpr[:stop_index], max_fpr)\n",
    "    else:\n",
    "        tpr = np.append(tpr, 1.0)\n",
    "        fpr = np.append(fpr, max_fpr)\n",
    "\n",
    "    # Calculate partial AUC\n",
    "    partial_auc_value = auc(fpr, tpr)\n",
    "\n",
    "    return partial_auc_value\n",
    "\n",
    "def cross_val_partial_auc_score(X, y, model, n_splits):\n",
    "\n",
    "     # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    pauc_scores = []\n",
    "    cont = 1\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "        print(f'\\rProcessing fold {cont} of {n_splits}...', end='', flush=True)\n",
    "        \n",
    "        # Create the folds\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                \n",
    "        # Train the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "        # Predict on the validation set\n",
    "        preds = model.predict_proba(X_val_fold)[:,1]\n",
    "    \n",
    "        # Calculate partical AUC and store it\n",
    "        pauc = partial_auc_score(y_val_fold, preds)\n",
    "        pauc_scores.append(pauc)\n",
    "        \n",
    "        cont = cont + 1\n",
    "        \n",
    "    # Return the average\n",
    "    return np.mean(pauc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70699db-dd46-4fac-8217-3066d142c8a7",
   "metadata": {},
   "source": [
    "# Model Loading and Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2668c8fe-ed34-4cfc-9047-d4e643d26038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metadata-based feature set\n",
    "ROOT_DATASET_DIR = \"./\"\n",
    "file_name_data = os.path.join(ROOT_DATASET_DIR,\"train-metadata-eda-fe.csv\")\n",
    "df_data = pd.read_csv(file_name_data)\n",
    "\n",
    "# Read the image (pixel)-based feature set\n",
    "file_name_img = os.path.join(ROOT_DATASET_DIR,\"train-cnn-features-rn152v2.csv\")\n",
    "df_img = pd.read_csv(file_name_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "263e30ee-ae18-45c6-bbf1-914c3fbce971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.drop(columns=['isic_id'], inplace=True)\n",
    "df_data['anatom_site_general'] = pd.Categorical(df_data['anatom_site_general'])\n",
    "df_data['tbp_lv_location'] = pd.Categorical(df_data['tbp_lv_location'])\n",
    "df_data['tbp_lv_location_simple'] = pd.Categorical(df_data['tbp_lv_location_simple'])\n",
    "df_data['sex'] = pd.Categorical(df_data['sex'])\n",
    "df_img.drop(columns=['target'], inplace=True)\n",
    "df = pd.concat([df_data, df_img], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ba01303-7b84-449e-8e40-8c367efa51cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>tbp_lv_Aext</th>\n",
       "      <th>tbp_lv_B</th>\n",
       "      <th>tbp_lv_Bext</th>\n",
       "      <th>...</th>\n",
       "      <th>im_feature_54</th>\n",
       "      <th>im_feature_55</th>\n",
       "      <th>im_feature_56</th>\n",
       "      <th>im_feature_57</th>\n",
       "      <th>im_feature_58</th>\n",
       "      <th>im_feature_59</th>\n",
       "      <th>im_feature_60</th>\n",
       "      <th>im_feature_61</th>\n",
       "      <th>im_feature_62</th>\n",
       "      <th>im_feature_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>20.244422</td>\n",
       "      <td>16.261975</td>\n",
       "      <td>26.922447</td>\n",
       "      <td>23.954773</td>\n",
       "      <td>...</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.363</td>\n",
       "      <td>6.310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>2.627</td>\n",
       "      <td>3.842</td>\n",
       "      <td>2.242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "      <td>31.712570</td>\n",
       "      <td>25.364740</td>\n",
       "      <td>26.331000</td>\n",
       "      <td>24.549290</td>\n",
       "      <td>...</td>\n",
       "      <td>3.277</td>\n",
       "      <td>2.197</td>\n",
       "      <td>5.420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.885</td>\n",
       "      <td>1.667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "      <td>22.575830</td>\n",
       "      <td>17.128170</td>\n",
       "      <td>37.970460</td>\n",
       "      <td>33.485410</td>\n",
       "      <td>...</td>\n",
       "      <td>3.844</td>\n",
       "      <td>2.775</td>\n",
       "      <td>6.720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.877</td>\n",
       "      <td>2.416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "      <td>14.242329</td>\n",
       "      <td>12.164757</td>\n",
       "      <td>21.448144</td>\n",
       "      <td>21.121356</td>\n",
       "      <td>...</td>\n",
       "      <td>3.650</td>\n",
       "      <td>2.547</td>\n",
       "      <td>6.395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.803</td>\n",
       "      <td>2.271</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0</td>\n",
       "      <td>24.725520</td>\n",
       "      <td>20.057470</td>\n",
       "      <td>26.464900</td>\n",
       "      <td>25.710460</td>\n",
       "      <td>...</td>\n",
       "      <td>3.328</td>\n",
       "      <td>2.330</td>\n",
       "      <td>5.574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>2.488</td>\n",
       "      <td>3.332</td>\n",
       "      <td>2.027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  age_approx sex anatom_site_general  clin_size_long_diam_mm  \\\n",
       "0       0        60.0   0     lower extremity                    3.04   \n",
       "1       0        60.0   0           head/neck                    1.10   \n",
       "2       0        60.0   0     posterior torso                    3.40   \n",
       "3       0        65.0   0      anterior torso                    3.22   \n",
       "4       0        55.0   0      anterior torso                    2.73   \n",
       "\n",
       "   tbp_tile_type   tbp_lv_A  tbp_lv_Aext   tbp_lv_B  tbp_lv_Bext  ...  \\\n",
       "0              0  20.244422    16.261975  26.922447    23.954773  ...   \n",
       "1              0  31.712570    25.364740  26.331000    24.549290  ...   \n",
       "2              1  22.575830    17.128170  37.970460    33.485410  ...   \n",
       "3              1  14.242329    12.164757  21.448144    21.121356  ...   \n",
       "4              0  24.725520    20.057470  26.464900    25.710460  ...   \n",
       "\n",
       "   im_feature_54  im_feature_55  im_feature_56  im_feature_57  im_feature_58  \\\n",
       "0          3.312          2.363          6.310            0.0            0.0   \n",
       "1          3.277          2.197          5.420            0.0            0.0   \n",
       "2          3.844          2.775          6.720            0.0            0.0   \n",
       "3          3.650          2.547          6.395            0.0            0.0   \n",
       "4          3.328          2.330          5.574            0.0            0.0   \n",
       "\n",
       "   im_feature_59  im_feature_60  im_feature_61  im_feature_62  im_feature_63  \n",
       "0         0.8320          2.627          3.842          2.242            0.0  \n",
       "1         0.6885          2.225          2.885          1.667            0.0  \n",
       "2         1.0700          2.955          3.877          2.416            0.0  \n",
       "3         0.9190          2.780          3.803          2.271            0.0  \n",
       "4         0.8813          2.488          3.332          2.027            0.0  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "701db7bd-99b3-4fc8-8319-55e01d5f00bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_approx</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>57.946816</td>\n",
       "      <td>13.546105</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>85.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>3.930147</td>\n",
       "      <td>1.741947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>3.37000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>28.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.710966</td>\n",
       "      <td>0.453314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>19.961896</td>\n",
       "      <td>3.993054</td>\n",
       "      <td>-2.487115</td>\n",
       "      <td>17.325051</td>\n",
       "      <td>19.79291</td>\n",
       "      <td>22.289341</td>\n",
       "      <td>48.18961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_59</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.719197</td>\n",
       "      <td>0.257739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.893600</td>\n",
       "      <td>1.73500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_60</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>2.097273</td>\n",
       "      <td>0.760955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.753000</td>\n",
       "      <td>2.23400</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4.73400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_61</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>2.809590</td>\n",
       "      <td>1.064116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>2.97500</td>\n",
       "      <td>3.518000</td>\n",
       "      <td>7.11300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_62</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>1.712804</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.404000</td>\n",
       "      <td>1.83200</td>\n",
       "      <td>2.146000</td>\n",
       "      <td>3.98800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im_feature_63</th>\n",
       "      <td>395303.0</td>\n",
       "      <td>0.054119</td>\n",
       "      <td>0.369634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.39000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count       mean        std       min        25%  \\\n",
       "target                  395303.0   0.000994   0.031515  0.000000   0.000000   \n",
       "age_approx              395303.0  57.946816  13.546105  5.000000  50.000000   \n",
       "clin_size_long_diam_mm  395303.0   3.930147   1.741947  1.000000   2.840000   \n",
       "tbp_tile_type           395303.0   0.710966   0.453314  0.000000   0.000000   \n",
       "tbp_lv_A                395303.0  19.961896   3.993054 -2.487115  17.325051   \n",
       "...                          ...        ...        ...       ...        ...   \n",
       "im_feature_59           395303.0   0.719197   0.257739  0.000000   0.587000   \n",
       "im_feature_60           395303.0   2.097273   0.760955  0.000000   1.753000   \n",
       "im_feature_61           395303.0   2.809590   1.064116  0.000000   2.287000   \n",
       "im_feature_62           395303.0   1.712804   0.642774  0.000000   1.404000   \n",
       "im_feature_63           395303.0   0.054119   0.369634  0.000000   0.000000   \n",
       "\n",
       "                             50%        75%       max  \n",
       "target                   0.00000   0.000000   1.00000  \n",
       "age_approx              60.00000  70.000000  85.00000  \n",
       "clin_size_long_diam_mm   3.37000   4.380000  28.40000  \n",
       "tbp_tile_type            1.00000   1.000000   1.00000  \n",
       "tbp_lv_A                19.79291  22.289341  48.18961  \n",
       "...                          ...        ...       ...  \n",
       "im_feature_59            0.76000   0.893600   1.73500  \n",
       "im_feature_60            2.23400   2.600000   4.73400  \n",
       "im_feature_61            2.97500   3.518000   7.11300  \n",
       "im_feature_62            1.83200   2.146000   3.98800  \n",
       "im_feature_63            0.00000   0.000000  12.39000  \n",
       "\n",
       "[188 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f0367-8caa-4ff7-aa2e-d7e4789ccecf",
   "metadata": {},
   "source": [
    "# Feature Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139c46c-3af3-4c68-b648-5a793b42b5ea",
   "metadata": {},
   "source": [
    "Some new features are from other notebooks at: https://www.kaggle.com/competitions/isic-2024-challenge/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08e08914-1538-4ad4-be51-15b5ede13b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original feature names\n",
    "features_to_be_logtr = ['clin_size_long_diam_mm',\n",
    "                        'tbp_lv_areaMM2',\n",
    "                        'tbp_lv_area_perim_ratio',\n",
    "                        'tbp_lv_color_std_mean',\n",
    "                        'tbp_lv_deltaLB',\n",
    "                        'tbp_lv_deltaLBnorm',\n",
    "                        'tbp_lv_minorAxisMM',\n",
    "                        'tbp_lv_norm_border',\n",
    "                        'tbp_lv_norm_color',\n",
    "                        'tbp_lv_perimeterMM',\n",
    "                        'tbp_lv_radial_color_std_max',\n",
    "                        'tbp_lv_stdL',\n",
    "                        'tbp_lv_stdLExt',\n",
    "                        'tbp_lv_symm_2axis']\n",
    "features_to_be_sqrtr = ['tbp_lv_eccentricity']\n",
    "\n",
    "# Modified original feature names\n",
    "log_features = ['log_' + col for col in features_to_be_logtr]\n",
    "sqr_features = ['sqr_' + col for col in features_to_be_sqrtr]\n",
    "\n",
    "# New feature names\n",
    "new_features_to_be_logtr = ['hue_contrast',\n",
    "                            'luminance_contrast',\n",
    "                            'lesion_color_difference',\n",
    "                            'border_complexity',\n",
    "                            'perimeter_to_area_ratio',\n",
    "                            'area_to_perimeter_ratio',\n",
    "                            'lesion_visibility_score',\n",
    "                            'symmetry_border_consistency',\n",
    "                            'consistency_symmetry_border',\n",
    "                            'consistency_color',\n",
    "                            'size_age_interaction',\n",
    "                            'lesion_severity_index',\n",
    "                            'shape_complexity_index',\n",
    "                            'std_dev_contrast',\n",
    "                            'color_shape_composite_index',\n",
    "                            'symmetry_perimeter_interaction',\n",
    "                            'comprehensive_lesion_index',\n",
    "                            'border_color_interaction',\n",
    "                            'size_color_contrast_ratio',\n",
    "                            'age_normalized_nevi_confidence',\n",
    "                            'volume_approximation_3d',\n",
    "                            'color_range',\n",
    "                            'age_size_symmetry_index',\n",
    "                            'index_age_size_symmetry']\n",
    "new_features_to_be_sqrtr = ['lesion_shape_index',\n",
    "                            'position_distance_3d']\n",
    "new_features_to_be_sqrttr = ['color_consistency',\n",
    "                             'hue_color_std_interaction',\n",
    "                             'normalized_lesion_size',                            \n",
    "                             'color_variance_ratio',\n",
    "                             'color_asymmetry_index',\n",
    "                             'shape_color_consistency']\n",
    "\n",
    "# Modify the column names\n",
    "log_new_features = ['log_' + col for col in new_features_to_be_logtr]\n",
    "sqr_new_features = ['sqr_' + col for col in new_features_to_be_sqrtr]\n",
    "sqrt_new_features = ['sqrt_' + col for col in new_features_to_be_sqrttr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dadd9db-35e8-4200-b759-22249bb1ed72",
   "metadata": {},
   "source": [
    "# Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "338967ee-6d89-4b7d-a463-11714c73d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "# Drop non-used features for the baseline + target\n",
    "X = df.drop(['target']\n",
    "             + features_to_be_logtr + features_to_be_sqrtr                                         # drop original features with skeweness (no transformation)                          \n",
    "             + new_features_to_be_logtr + new_features_to_be_sqrtr + new_features_to_be_sqrttr,    # drop new features with skeweness (no transformation)             \n",
    "             axis=1)\n",
    "y = df['target']\n",
    "#X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=TRAIN_TEST_SPLIT, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20253c01-6731-4329-aeba-4fb48c3dc7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['age_approx', 'tbp_tile_type', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_nevi_confidence', 'tbp_lv_symm_2axis_angle', 'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'log_clin_size_long_diam_mm', 'log_tbp_lv_areaMM2', 'log_tbp_lv_area_perim_ratio', 'log_tbp_lv_color_std_mean', 'log_tbp_lv_deltaLB', 'log_tbp_lv_deltaLBnorm', 'log_tbp_lv_minorAxisMM', 'log_tbp_lv_norm_border', 'log_tbp_lv_norm_color', 'log_tbp_lv_perimeterMM', 'log_tbp_lv_radial_color_std_max', 'log_tbp_lv_stdL', 'log_tbp_lv_stdLExt', 'log_tbp_lv_symm_2axis', 'sqr_tbp_lv_eccentricity', 'lesion_size_ratio', 'color_contrast_index', 'log_lesion_area', 'mean_hue_difference', 'lesion_orientation_3d', 'overall_color_difference', 'border_color_interaction_2', 'age_normalized_nevi_confidence_2', 'border_length_ratio', 'log_hue_contrast', 'log_luminance_contrast', 'log_lesion_color_difference', 'log_border_complexity', 'log_perimeter_to_area_ratio', 'log_area_to_perimeter_ratio', 'log_lesion_visibility_score', 'log_symmetry_border_consistency', 'log_consistency_symmetry_border', 'log_consistency_color', 'log_size_age_interaction', 'log_lesion_severity_index', 'log_shape_complexity_index', 'log_std_dev_contrast', 'log_color_shape_composite_index', 'log_symmetry_perimeter_interaction', 'log_comprehensive_lesion_index', 'log_border_color_interaction', 'log_size_color_contrast_ratio', 'log_age_normalized_nevi_confidence', 'log_volume_approximation_3d', 'log_color_range', 'log_age_size_symmetry_index', 'log_index_age_size_symmetry', 'sqr_lesion_shape_index', 'sqr_position_distance_3d', 'sqrt_color_consistency', 'sqrt_hue_color_std_interaction', 'sqrt_normalized_lesion_size', 'sqrt_color_variance_ratio', 'sqrt_color_asymmetry_index', 'sqrt_shape_color_consistency', 'im_feature_0', 'im_feature_1', 'im_feature_2', 'im_feature_3', 'im_feature_4', 'im_feature_5', 'im_feature_6', 'im_feature_7', 'im_feature_8', 'im_feature_9', 'im_feature_10', 'im_feature_11', 'im_feature_12', 'im_feature_13', 'im_feature_14', 'im_feature_15', 'im_feature_16', 'im_feature_17', 'im_feature_18', 'im_feature_19', 'im_feature_20', 'im_feature_21', 'im_feature_22', 'im_feature_23', 'im_feature_24', 'im_feature_25', 'im_feature_26', 'im_feature_27', 'im_feature_28', 'im_feature_29', 'im_feature_30', 'im_feature_31', 'im_feature_32', 'im_feature_33', 'im_feature_34', 'im_feature_35', 'im_feature_36', 'im_feature_37', 'im_feature_38', 'im_feature_39', 'im_feature_40', 'im_feature_41', 'im_feature_42', 'im_feature_43', 'im_feature_44', 'im_feature_45', 'im_feature_46', 'im_feature_47', 'im_feature_48', 'im_feature_49', 'im_feature_50', 'im_feature_51', 'im_feature_52', 'im_feature_53', 'im_feature_54', 'im_feature_55', 'im_feature_56', 'im_feature_57', 'im_feature_58', 'im_feature_59', 'im_feature_60', 'im_feature_61', 'im_feature_62', 'im_feature_63'] - Length: 140\n",
      "Categorical features: ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple'] - Length: 4\n"
     ]
    }
   ],
   "source": [
    "numerical_features = X.select_dtypes(include=['float64','int64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
    "print(f\"Numerical features: {numerical_features} - Length: {len(numerical_features)}\")\n",
    "print(f\"Categorical features: {categorical_features} - Length: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efbb88-9160-4eb4-947a-92fe29f5a4ff",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9f1bbbf-0333-4536-a7ea-ef055103995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant numerical features: 131\n",
      "\n",
      "                                        Score   P-Value\n",
      "Feature                                                \n",
      "im_feature_28                    38498.512139  0.000000\n",
      "im_feature_17                    37569.437479  0.000000\n",
      "im_feature_10                    37105.093383  0.000000\n",
      "im_feature_29                    37097.916715  0.000000\n",
      "im_feature_19                    36514.406202  0.000000\n",
      "...                                       ...       ...\n",
      "lesion_size_ratio                   10.627077  0.001115\n",
      "log_symmetry_border_consistency      8.738379  0.003116\n",
      "tbp_lv_L                             6.699025  0.009647\n",
      "sqrt_hue_color_std_interaction       6.449304  0.011100\n",
      "sqrt_color_variance_ratio            3.877523  0.048937\n",
      "\n",
      "[131 rows x 2 columns]\n",
      "Number of relevant categorical features: 8\n",
      "\n",
      "                                              Score       P-Value\n",
      "Feature                                                          \n",
      "anatom_site_general_head/neck            364.361682  3.161229e-81\n",
      "tbp_lv_location_Right Leg - Upper         15.614025  7.767632e-05\n",
      "tbp_lv_location_simple_Right Leg           8.605018  3.352381e-03\n",
      "anatom_site_general_lower extremity        8.463089  3.624258e-03\n",
      "tbp_lv_location_Left Leg                   8.314718  3.932510e-03\n",
      "tbp_lv_location_Torso Front Bottom Half    5.201509  2.256728e-02\n",
      "tbp_lv_location_Torso Back Middle Third    4.221756  3.990885e-02\n",
      "tbp_lv_location_Left Leg - Upper           3.866920  4.924681e-02\n"
     ]
    }
   ],
   "source": [
    "# Use SelectKBest (f_classif) for numerical features\n",
    "Kbest_numerical = SelectKBest(score_func=f_classif, k='all')\n",
    "Kbest_numerical.fit(X[numerical_features], y)\n",
    "\n",
    "# Extract feature scores and p-values\n",
    "scores = Kbest_numerical.scores_\n",
    "pvalues = Kbest_numerical.pvalues_\n",
    "\n",
    "# Create a DataFrame to save feature names, scores, and p-values\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Score': scores,\n",
    "    'P-Value': pvalues\n",
    "})\n",
    "\n",
    "# Sort features by 'Score'\n",
    "best_feature_scores = feature_scores[feature_scores['P-Value'] < 0.05]\n",
    "sorted_features = best_feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Display the sorted features\n",
    "KBEST_NUM = sorted_features.shape[0]\n",
    "print(f\"Number of relevant numerical features: {KBEST_NUM}\\n\")\n",
    "print(sorted_features.set_index('Feature'))\n",
    "\n",
    "# Use SelectKBest (chi2) for categorical features\n",
    "\n",
    "# Build a pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('onehot', preprocessor),\n",
    "    ('kbest', SelectKBest(score_func=chi2, k='all'))\n",
    "])\n",
    "\n",
    "cat_transformed = pipeline.fit_transform(X, y)\n",
    "Kbest_categorical = pipeline.named_steps['kbest']\n",
    "\n",
    "# Extract feature scores and p-values\n",
    "scores = Kbest_categorical.scores_\n",
    "pvalues = Kbest_categorical.pvalues_\n",
    "\n",
    "# Extract feature names after one-hot encoding\n",
    "one_hot_feature_names = pipeline.named_steps['onehot'].transformers_[0][1].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Create a DataFrame to hold feature names, scores, and p-values\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': one_hot_feature_names,\n",
    "    'Score': scores,\n",
    "    'P-Value': pvalues\n",
    "})\n",
    "\n",
    "# Sort features by their scores\n",
    "best_feature_scores = feature_scores[feature_scores['P-Value'] < 0.05]\n",
    "sorted_features = best_feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Display the sorted features\n",
    "KBEST_CAT = sorted_features.shape[0]\n",
    "print(f\"Number of relevant categorical features: {KBEST_CAT}\\n\")\n",
    "print(sorted_features.set_index('Feature'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d1e34-3ff4-4b41-a175-dd575cbdf9e3",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7ea1aeb-c796-42c2-a8e0-407d2110162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "   \n",
    "pipe_num = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('kbest', SelectKBest(score_func=f_classif, k=KBEST_NUM)),   \n",
    "])\n",
    "\n",
    "pipe_cat = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)),\n",
    "    ('kbest', SelectKBest(score_func=chi2, k=KBEST_CAT)),    \n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer(transformers=[\n",
    "    ('numerical', pipe_num, numerical_features),\n",
    "    ('categorical',pipe_cat, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369183e0-1e6b-4909-81ff-e11389f7d710",
   "metadata": {},
   "source": [
    "# Balanced Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd36609-43cf-4470-885b-55f387672192",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a92a5549-b2f0-4b33-9264-3805fb66fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['rf']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "        # Suggest values for the hyperparameters\n",
    "        n_estimators = trial.suggest_int('n_estimators', 100, 400)\n",
    "        max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10) #7)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10) #5)   \n",
    "        bootstrap=True\n",
    "        class_weight='balanced_subsample'\n",
    "    \n",
    "        pauc_scores = []\n",
    "    \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            \n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                        \n",
    "            # Pipeline                           \n",
    "            pipe_rf = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('RF', BalancedRandomForestClassifier(random_state=42,\n",
    "                                                      n_estimators=n_estimators,\n",
    "                                                      max_depth=max_depth,\n",
    "                                                      min_samples_split=min_samples_split,\n",
    "                                                      min_samples_leaf=min_samples_leaf,\n",
    "                                                      bootstrap=bootstrap,\n",
    "                                                      class_weight=class_weight\n",
    "                                                     )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_rf.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_rf.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "    \n",
    "#Best trial number: 18\n",
    "#Best value (partial auc - 0.8): 0.19099394435542486\n",
    "#Best hyperparameters: {'n_estimators': 138, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb8084-17ee-40c4-b354-6ce04033fafa",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d0ac8a7-be36-4596-b3dd-782059669ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Partial AUC Score: 0.19099394435542486\n"
     ]
    }
   ],
   "source": [
    "param_rf = {\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 138,\n",
    "        'max_depth': 12,\n",
    "        'min_samples_split': 5,\n",
    "        'min_samples_leaf': 8,\n",
    "        'bootstrap': True,\n",
    "        'class_weight': 'balanced_subsample',\n",
    "        'n_jobs': -1\n",
    "}\n",
    "\n",
    "model_rf_cv = ImbPipeline([    \n",
    "    ('preprocessing', preprocessing),\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "    ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "    ('RF',  BalancedRandomForestClassifier(**param_rf))\n",
    "])\n",
    "\n",
    "if ENABLE['rf']['compute-pauc'] == 1:\n",
    "    pauc_rf_cv = cross_val_partial_auc_score(X, y, model_rf_cv, n_splits=5)    \n",
    "    print(f\"CV Partial AUC Score: {pauc_rf_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46150e09-685c-4105-9b33-05db0bf36755",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae79e0c8-b308-4ce2-ba32-05986a0decdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['rf']['final-train'] == 1:\n",
    "    \n",
    "    model_rf_fe139_rsmpl = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('RF',  BalancedRandomForestClassifier(**param_rf))\n",
    "    ])\n",
    "    \n",
    "    model_rf_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421dda50-dac8-4330-b5a2-308d6fd0be24",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20321e83-57b0-4d33-be7a-f28f0ad7c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['rf']['save-model'] == 1:\n",
    "    dump(model_rf_fe139_rsmpl, 'model_rf_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6501f-5cdb-48da-9892-987af7a88f6d",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47aed3d-aefa-41ee-82fd-603a27dedee3",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1202ac58-2815-4634-b924-838c0495159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['xgb']['cross-val'] == 1:\n",
    "\n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "        # Suggest values for the hyperparameters\n",
    "        #n_estimators = trial.suggest_int('n_estimators', 200, 400)\n",
    "        #learning_rate = trial.suggest_float('learning_rate', 0.083, 0.087)\n",
    "        #reg_lambda = trial.suggest_float('reg_lambda', 8.0, 9.0)\n",
    "        #alpha = trial.suggest_float('alpha', 0.6, 0.7)\n",
    "        #max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "        #subsample = trial.suggest_float('subsample', 0.5, 0.7)\n",
    "        #colsample_bytree = trial.suggest_float('colsample_bytree', 0.85, 0.95)\n",
    "        #colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.5, 0.6)\n",
    "        #scale_pos_weight = trial.suggest_float('scale_pos_weight', 3.2, 3.5)    \n",
    "        # Suggest values for the hyperparameters\n",
    "        n_estimators = trial.suggest_int('n_estimators', 200, 400)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.080, 0.090)\n",
    "        reg_lambda = trial.suggest_float('reg_lambda', 5.0, 10.0)\n",
    "        alpha = trial.suggest_float('alpha', 0.5, 0.8)\n",
    "        max_depth = trial.suggest_int('max_depth', 10, 31)\n",
    "        subsample = trial.suggest_float('subsample', 0.45, 0.70)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.80, 1.0)\n",
    "        colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.4, 0.7)\n",
    "        scale_pos_weight = trial.suggest_float('scale_pos_weight', 1, 10)\n",
    "        eval_metric = 'logloss'\n",
    "        enable_categorical = True\n",
    "    \n",
    "        pauc_scores = []\n",
    "    \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            \n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                    \n",
    "            # Pipeline                           \n",
    "            pipe_xgb = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('XGB', XGBClassifier(random_state=42,\n",
    "                                      enable_categorical=enable_categorical,\n",
    "                                      eval_metric=eval_metric,\n",
    "                                      n_estimators=n_estimators,\n",
    "                                      learning_rate=learning_rate,\n",
    "                                      reg_lambda=reg_lambda,\n",
    "                                      alpha=alpha,\n",
    "                                      max_depth=max_depth,\n",
    "                                      subsample=subsample,\n",
    "                                      colsample_bytree=colsample_bytree,\n",
    "                                      colsample_bylevel=colsample_bylevel,                             \n",
    "                                      scale_pos_weight=scale_pos_weight,\n",
    "                                    )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_xgb.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_xgb.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "    \n",
    "#Best trial number: 80\n",
    "#Best value (partial auc - 0.8): 0.1917259326323112\n",
    "#Best hyperparameters: {'n_estimators': 208, 'learning_rate': 0.08256404336718554, 'reg_lambda': 6.1374965163887305, 'alpha': 0.6026870768041418, 'max_depth': 21, 'subsample': 0.47434308951793386, 'colsample_bytree': 0.9081510010036246, 'colsample_bylevel': 0.5171030271682259, 'scale_pos_weight': 9.454864886835315}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebc687-989a-47e9-b524-9dbcc6b7e7b1",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28ed626e-6394-44ef-b5f3-2c15f2ec3298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Partial AUC Score: 0.1917259326323112\n"
     ]
    }
   ],
   "source": [
    "param_xgb = {\n",
    "        'random_state':      42,\n",
    "        'n_estimators':      208,\n",
    "        'learning_rate':     0.08256404336718554,\n",
    "        'reg_lambda':        6.1374965163887305,\n",
    "        'alpha':             0.6026870768041418,\n",
    "        'max_depth':         21,\n",
    "        'subsample':         0.47434308951793386,\n",
    "        'colsample_bytree':  0.9081510010036246,\n",
    "        'colsample_bylevel': 0.5171030271682259,\n",
    "        'scale_pos_weight':  9.454864886835315\n",
    "    }\n",
    "\n",
    "model_xgb_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('RF',  XGBClassifier(**param_xgb))\n",
    "    ])\n",
    "\n",
    "if ENABLE['xgb']['compute-pauc'] == 1:\n",
    "    pauc_xgb_cv = cross_val_partial_auc_score(X, y, model_xgb_cv, n_splits=5)    \n",
    "    print(f\"CV Partial AUC Score: {pauc_xgb_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f9aef-c4db-40c9-a86e-4a7d06942446",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b36531ee-1dc3-45e0-9a33-6b90c2bc07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['xgb']['final-train'] == 1:\n",
    "                           \n",
    "    model_xgb_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('XGB', XGBClassifier(**param_xgb))\n",
    "    ])\n",
    "    \n",
    "    model_xgb_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308ee8b-6035-4afc-86b0-ec6016516876",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e6fa867-1b9a-4f68-8944-b7d7cd5a499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['xgb']['save-model'] == 1:\n",
    "    dump(model_xgb_fe139_rsmpl, 'model_xgb_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7e44e-7a7c-49b0-85a2-016f63d7b1c9",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9abab-1503-49d3-9584-dc4ef04d138b",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ceeb482-0711-4561-baf7-e0a91be4beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lgb']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "        \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        objective = 'binary'\n",
    "        boosting_type = 'gbdt'\n",
    "        verbosity = -1\n",
    "        n_estimators = trial.suggest_int('n_estimators', 200, 500)    \n",
    "        lambda_l1 = trial.suggest_float('lambda_l1', 0.05, 0.10)\n",
    "        lambda_l2 = trial.suggest_float('lambda_l2', 0.001, 0.010)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 1.0)\n",
    "        max_depth = trial.suggest_int('max_depth', 20, 50)    \n",
    "        num_leaves = trial.suggest_int('num_leaves', 20, 20)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "        colsample_bynode = trial.suggest_float('colsample_bynode', 0.1, 1.0)\n",
    "        bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0) \n",
    "        bagging_freq = trial.suggest_int('bagging_freq', 0, 15)\n",
    "        min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 10)\n",
    "        scale_pos_weight = trial.suggest_float('scale_pos_weight', 1.0, 10.0)\n",
    "    \n",
    "        pauc_scores = []\n",
    "    \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                        \n",
    "            # Pipeline\n",
    "            pipe_lgb = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('LGB', LGBMClassifier(random_state=random_state,\n",
    "                                       verbosity=verbosity,\n",
    "                                       objective=objective,\n",
    "                                       boosting_type=boosting_type,                                   \n",
    "                                       n_estimators=n_estimators,\n",
    "                                       lambda_l1=lambda_l1,\n",
    "                                       lambda_l2=lambda_l2,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       max_depth=max_depth,\n",
    "                                       num_leaves=num_leaves,\n",
    "                                       colsample_bytree=colsample_bytree,\n",
    "                                       colsample_bynode=colsample_bynode,\n",
    "                                       bagging_fraction=bagging_fraction,\n",
    "                                       bagging_freq=bagging_freq,\n",
    "                                       min_data_in_leaf=min_data_in_leaf,\n",
    "                                       scale_pos_weight=scale_pos_weight\n",
    "                                      )         \n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_lgb.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_lgb.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "        \n",
    "#Best value (partial auc - 0.8): 0.19165167013143908\n",
    "#Best hyperparameters: {'n_estimators': 390, 'lambda_l1': 0.05127158993500609, 'lambda_l2': 0.002856268451232568, 'learning_rate': 0.016316428473444125, 'max_depth': 32, 'num_leaves': 20, 'colsample_bytree': 0.501841654985379, 'colsample_bynode': 0.3253277554214308, 'bagging_fraction': 0.22054551329713584, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'scale_pos_weight': 1.0154421072327424}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfc6ca-b371-4604-a0e9-0c6f89134edf",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1672880-21ac-420e-b42d-536134720723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Partial AUC Score: 0.19165167013143908\n"
     ]
    }
   ],
   "source": [
    "param_lgb = {\n",
    "        'random_state':     42,\n",
    "        'objective':        'binary',\n",
    "        'boosting_type':    'gbdt',\n",
    "        'verbosity':        -1,\n",
    "        'n_estimators':     390,\n",
    "        'lambda_l1':        0.05127158993500609,\n",
    "        'lambda_l2':        0.002856268451232568,\n",
    "        'learning_rate':    0.016316428473444125,\n",
    "        'max_depth':        32,\n",
    "        'num_leaves':       20,\n",
    "        'colsample_bytree': 0.501841654985379, \n",
    "        'colsample_bynode': 0.3253277554214308,\n",
    "        'bagging_fraction': 0.22054551329713584,\n",
    "        'bagging_freq':     5,\n",
    "        'min_data_in_leaf': 9,\n",
    "        'scale_pos_weight': 1.0154421072327424,\n",
    "    }\n",
    "\n",
    "\n",
    "model_lgb_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('LGB',  LGBMClassifier(**param_lgb))\n",
    "    ])\n",
    "\n",
    "if ENABLE['lgb']['compute-pauc'] == 1:\n",
    "    pauc_lgb_cv = cross_val_partial_auc_score(X, y, model_lgb_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_lgb_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b25bf-63ee-4db4-bc7a-3b724e35592a",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8052b1b2-30d6-482a-9991-0bae08ca26ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lgb']['final-train'] == 1:\n",
    "    \n",
    "    # Pipeline                          \n",
    "    model_lgb_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),  \n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "        ('LGB', LGBMClassifier(**param_lgb))\n",
    "    ])\n",
    "    \n",
    "    model_lgb_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95539a1-0871-41b9-8beb-1f8f07d1b6c6",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4085524-87a9-4c20-ac12-c2bce12ac75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['lgb']['save-model'] == 1:\n",
    "    dump(model_lgb_fe139_rsmpl, 'model_lgb_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81f006-c34d-4841-8029-f0fee4518b8a",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c1058-b9c6-47de-9a5b-6b170f40d659",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8032cbd-8f95-4e76-98f5-0519b31b0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['cb']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "            \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        loss_function = 'Logloss'\n",
    "        verbose = False\n",
    "        n_estimators = trial.suggest_int('n_estimators', 200, 400)    \n",
    "        max_depth = trial.suggest_int('max_depth', 1, 16)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 1.0)    \n",
    "        scale_pos_weight = trial.suggest_float('scale_pos_weight', 1.0, 10.0) #4.0)\n",
    "        l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1.0, 10.0) #8.0)\n",
    "        subsample = trial.suggest_float('subsample', 0.1, 1.0) #0.8)\n",
    "        min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 35) # 15, 35)\n",
    "        \n",
    "        pauc_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                    \n",
    "            # Pipeline\n",
    "            pipe_cb = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),  \n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "                ('CAT', CatBoostClassifier(random_state=random_state,                               \n",
    "                                           loss_function=loss_function,\n",
    "                                           verbose=verbose,\n",
    "                                           n_estimators=n_estimators,                               \n",
    "                                           max_depth=max_depth,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           scale_pos_weight=scale_pos_weight,\n",
    "                                           l2_leaf_reg=l2_leaf_reg,\n",
    "                                           subsample=subsample,\n",
    "                                           min_data_in_leaf=min_data_in_leaf,\n",
    "                                        )         \n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_cb.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_cb.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "    \n",
    "#TRIAL 2\n",
    "#{'n_estimators': 214, 'max_depth': 6, 'learning_rate': 0.16562407742162114, 'scale_pos_weight': 1.7093579819808669, 'l2_leaf_reg': 7.02714772536825, 'subsample': 0.8505760501200976, 'min_data_in_leaf': 5}.\n",
    "#Best is trial 51 with value: 0.1648771759885043.\n",
    "\n",
    "# TRIAL\n",
    "#Trial 30 finished with value: 0.19182318666176065\n",
    "#and parameters: {'n_estimators': 352, 'max_depth': 12, 'learning_rate': 0.010916211896675203, 'scale_pos_weight': 1.1308423310589069, 'l2_leaf_reg': 9.938943422516182, 'subsample': 0.48191020552292485, 'min_data_in_leaf': 35}. Best is trial 30 with value: 0.19182318666176065."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb552cde-0c31-428b-be68-9ae476259979",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ee364d3-406c-443e-93ac-22f5ce38fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "Processing fold 2...\n",
      "Processing fold 3...\n",
      "Processing fold 4...\n",
      "Processing fold 5...\n",
      "CV Partial AUC Score: 0.19182318666176065\n"
     ]
    }
   ],
   "source": [
    "param_cb = {\n",
    "        'random_state':     42,\n",
    "        'loss_function':    'Logloss',\n",
    "        'verbose':          False,\n",
    "        'n_estimators':     352,\n",
    "        'max_depth':        12,\n",
    "        'learning_rate':    0.010916211896675203,\n",
    "        'scale_pos_weight': 1.1308423310589069,\n",
    "        'l2_leaf_reg':      9.938943422516182,\n",
    "        'subsample':        0.48191020552292485, \n",
    "        'min_data_in_leaf': 35\n",
    "    }\n",
    "\n",
    "model_cb_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('CB',  CatBoostClassifier(**param_cb))\n",
    "    ])\n",
    "\n",
    "if ENABLE['cb']['compute-pauc'] == 1:\n",
    "    pauc_cb_cv = cross_val_partial_auc_score(X, y, model_cb_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_cb_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01332b60-72f0-484c-8a5a-f368bf241279",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cd287d3-b3cc-418b-8e9c-9dd9f3399ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['cb']['final-train'] == 1:\n",
    "        \n",
    "    model_cb_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('CAT', CatBoostClassifier(**param_cb)         \n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model_cb_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afd986-e0c2-4256-9ab6-05edd7290ff1",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0df4f41b-db2f-4b1b-9ada-cedc5725f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['cb']['save-model'] == 1:\n",
    "    dump(model_cb_fe139_rsmpl, 'model_cb_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3eb52e-12db-412f-9b48-c96206c1fa07",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24a91d-1cd7-44e0-84df-456d0aadad8f",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47362f1-8505-4e68-98b1-adbfc8673567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-24 15:18:23,695] A new study created in memory with name: no-name-0496b580-86c2-4dcb-b5fe-2d48595284fd\n",
      "[I 2024-08-24 15:35:24,591] Trial 9 finished with value: 0.1914735240847279 and parameters: {'n_estimators': 155, 'learning_rate': 0.06325940927670827}. Best is trial 9 with value: 0.1914735240847279.\n",
      "[I 2024-08-24 15:35:49,592] Trial 13 finished with value: 0.18865451547508086 and parameters: {'n_estimators': 155, 'learning_rate': 0.5138905550970538}. Best is trial 9 with value: 0.1914735240847279.\n",
      "[I 2024-08-24 15:39:58,644] Trial 14 finished with value: 0.18936045214629119 and parameters: {'n_estimators': 204, 'learning_rate': 0.17675854316053655}. Best is trial 9 with value: 0.1914735240847279.\n",
      "[I 2024-08-24 15:40:47,000] Trial 0 finished with value: 0.19157837827477664 and parameters: {'n_estimators': 208, 'learning_rate': 0.0442257691513033}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:41:01,003] Trial 8 finished with value: 0.18364626424512515 and parameters: {'n_estimators': 210, 'learning_rate': 0.001213790364680854}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:41:28,845] Trial 11 finished with value: 0.1873391644897173 and parameters: {'n_estimators': 211, 'learning_rate': 0.004509806659807725}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:43:28,213] Trial 10 finished with value: 0.18981721413925112 and parameters: {'n_estimators': 232, 'learning_rate': 0.006464066553667055}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:43:51,231] Trial 2 finished with value: 0.18980366871622173 and parameters: {'n_estimators': 237, 'learning_rate': 0.14453612419690243}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:45:36,489] Trial 3 finished with value: 0.19130665255131363 and parameters: {'n_estimators': 256, 'learning_rate': 0.03437782763894559}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:46:07,768] Trial 5 finished with value: 0.1913251638294966 and parameters: {'n_estimators': 259, 'learning_rate': 0.023615764219491176}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:47:02,912] Trial 18 finished with value: 0.18958956783143815 and parameters: {'n_estimators': 64, 'learning_rate': 0.02175273288900237}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:47:46,545] Trial 15 finished with value: 0.18937212147538843 and parameters: {'n_estimators': 282, 'learning_rate': 0.004455510275872727}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:48:25,862] Trial 12 finished with value: 0.1904745170512887 and parameters: {'n_estimators': 282, 'learning_rate': 0.10399627332855929}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:48:50,118] Trial 6 finished with value: 0.1898687800556376 and parameters: {'n_estimators': 289, 'learning_rate': 0.0058415327002691395}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:52:59,045] Trial 7 finished with value: 0.19027327642001612 and parameters: {'n_estimators': 337, 'learning_rate': 0.00541421414943889}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:56:29,477] Trial 1 finished with value: 0.19027754830483373 and parameters: {'n_estimators': 367, 'learning_rate': 0.004985492868734452}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:58:32,546] Trial 23 finished with value: 0.18881447188764924 and parameters: {'n_estimators': 143, 'learning_rate': 0.3923716566642244}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:58:33,912] Trial 19 finished with value: 0.19079791305906113 and parameters: {'n_estimators': 174, 'learning_rate': 0.10630532166530395}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:58:42,647] Trial 4 finished with value: 0.1913939570424958 and parameters: {'n_estimators': 387, 'learning_rate': 0.01229789538257803}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 15:59:52,996] Trial 21 finished with value: 0.19049614877390086 and parameters: {'n_estimators': 180, 'learning_rate': 0.1191090570347019}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 16:05:01,941] Trial 17 finished with value: 0.19125373539737017 and parameters: {'n_estimators': 289, 'learning_rate': 0.013652619065214849}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 16:06:05,904] Trial 30 finished with value: 0.19133814905184537 and parameters: {'n_estimators': 126, 'learning_rate': 0.05571281025284476}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 16:08:09,344] Trial 33 finished with value: 0.19144300079493282 and parameters: {'n_estimators': 92, 'learning_rate': 0.0500818012662083}. Best is trial 0 with value: 0.19157837827477664.\n",
      "[I 2024-08-24 16:08:32,917] Trial 31 finished with value: 0.19171700903408395 and parameters: {'n_estimators': 116, 'learning_rate': 0.05598522139225104}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:09:20,976] Trial 35 finished with value: 0.19147403287160172 and parameters: {'n_estimators': 89, 'learning_rate': 0.053248828013095315}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:10:08,749] Trial 34 finished with value: 0.1912163168891492 and parameters: {'n_estimators': 108, 'learning_rate': 0.05057854227053018}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:11:28,594] Trial 24 finished with value: 0.191289867433589 and parameters: {'n_estimators': 253, 'learning_rate': 0.04821130800050667}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:13:22,871] Trial 32 finished with value: 0.19125636788010586 and parameters: {'n_estimators': 143, 'learning_rate': 0.055023910975635526}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:14:20,710] Trial 20 finished with value: 0.18403229809155974 and parameters: {'n_estimators': 333, 'learning_rate': 0.5267661234069607}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:14:35,919] Trial 16 finished with value: 0.1901358892030921 and parameters: {'n_estimators': 393, 'learning_rate': 0.15233116681336706}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:15:52,516] Trial 36 finished with value: 0.19152318613822097 and parameters: {'n_estimators': 102, 'learning_rate': 0.0525910936365145}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:16:24,305] Trial 41 finished with value: 0.1847743838215357 and parameters: {'n_estimators': 55, 'learning_rate': 0.9787645963710943}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:16:49,863] Trial 22 finished with value: 0.19159210228804838 and parameters: {'n_estimators': 331, 'learning_rate': 0.016074365502201253}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:17:59,682] Trial 37 finished with value: 0.19166552174209742 and parameters: {'n_estimators': 113, 'learning_rate': 0.05607400980544437}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:18:10,360] Trial 38 finished with value: 0.1914690172464079 and parameters: {'n_estimators': 92, 'learning_rate': 0.05854248285084803}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:18:57,578] Trial 39 finished with value: 0.18928329345185577 and parameters: {'n_estimators': 96, 'learning_rate': 0.26410733346158416}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:19:23,839] Trial 42 finished with value: 0.19078532184757954 and parameters: {'n_estimators': 70, 'learning_rate': 0.2783736150819807}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:20:17,568] Trial 40 finished with value: 0.18920918994431332 and parameters: {'n_estimators': 100, 'learning_rate': 0.2555437519095174}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:20:33,799] Trial 43 finished with value: 0.19057373731331645 and parameters: {'n_estimators': 62, 'learning_rate': 0.2627209585656579}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:21:11,118] Trial 44 finished with value: 0.19092578992706527 and parameters: {'n_estimators': 62, 'learning_rate': 0.2553927770258761}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:21:49,899] Trial 45 finished with value: 0.19076147025919427 and parameters: {'n_estimators': 64, 'learning_rate': 0.2699297850723344}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:22:48,020] Trial 46 finished with value: 0.1906110186807423 and parameters: {'n_estimators': 62, 'learning_rate': 0.26711468507862773}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:24:24,697] Trial 26 finished with value: 0.19100026098083173 and parameters: {'n_estimators': 374, 'learning_rate': 0.08355666317976783}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:24:27,100] Trial 25 finished with value: 0.18028868577905385 and parameters: {'n_estimators': 379, 'learning_rate': 0.6997349469964667}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:24:45,607] Trial 27 finished with value: 0.19072103212009622 and parameters: {'n_estimators': 371, 'learning_rate': 0.09250704954071863}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:25:13,300] Trial 28 finished with value: 0.19115454093291695 and parameters: {'n_estimators': 364, 'learning_rate': 0.05325282338814807}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:26:08,886] Trial 47 finished with value: 0.18950178912083063 and parameters: {'n_estimators': 91, 'learning_rate': 0.21255161301009157}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:26:14,690] Trial 29 finished with value: 0.19115636723985877 and parameters: {'n_estimators': 377, 'learning_rate': 0.05788932327733793}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:29:13,847] Trial 48 finished with value: 0.1897304894633485 and parameters: {'n_estimators': 119, 'learning_rate': 0.012372857968367715}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:36:30,818] Trial 58 finished with value: 0.1912619432078456 and parameters: {'n_estimators': 116, 'learning_rate': 0.0300853598702166}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:36:59,973] Trial 60 finished with value: 0.19128271928221946 and parameters: {'n_estimators': 119, 'learning_rate': 0.03203250707289734}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:37:07,398] Trial 61 finished with value: 0.191091039309093 and parameters: {'n_estimators': 115, 'learning_rate': 0.02850361704503147}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:38:53,076] Trial 62 finished with value: 0.191210581505629 and parameters: {'n_estimators': 122, 'learning_rate': 0.031864857559596484}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:45:56,630] Trial 67 finished with value: 0.18968498813101417 and parameters: {'n_estimators': 80, 'learning_rate': 0.01801395850463759}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:47:45,877] Trial 64 finished with value: 0.19151794733060962 and parameters: {'n_estimators': 180, 'learning_rate': 0.03012671298141839}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:51:27,665] Trial 49 finished with value: 0.1914334715283221 and parameters: {'n_estimators': 338, 'learning_rate': 0.012814276973377088}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:52:27,820] Trial 55 finished with value: 0.19170830631700095 and parameters: {'n_estimators': 312, 'learning_rate': 0.02352748206313035}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:53:13,317] Trial 50 finished with value: 0.19145425539996452 and parameters: {'n_estimators': 351, 'learning_rate': 0.025749705033605626}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:53:49,410] Trial 51 finished with value: 0.1912279418124028 and parameters: {'n_estimators': 351, 'learning_rate': 0.029258504792373463}. Best is trial 31 with value: 0.19171700903408395.\n",
      "[I 2024-08-24 16:54:43,092] Trial 52 finished with value: 0.1917190292233027 and parameters: {'n_estimators': 353, 'learning_rate': 0.026994932632169566}. Best is trial 52 with value: 0.1917190292233027.\n",
      "[I 2024-08-24 16:54:50,237] Trial 54 finished with value: 0.19167327518393726 and parameters: {'n_estimators': 339, 'learning_rate': 0.030805692014644104}. Best is trial 52 with value: 0.1917190292233027.\n",
      "[I 2024-08-24 16:55:39,774] Trial 53 finished with value: 0.19173484739529267 and parameters: {'n_estimators': 352, 'learning_rate': 0.022798770211700257}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 16:56:32,956] Trial 56 finished with value: 0.19157739550778788 and parameters: {'n_estimators': 349, 'learning_rate': 0.0275034089308889}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 16:57:27,739] Trial 59 finished with value: 0.1914786969772964 and parameters: {'n_estimators': 323, 'learning_rate': 0.026684370650894434}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 16:57:59,670] Trial 57 finished with value: 0.1912759580856269 and parameters: {'n_estimators': 342, 'learning_rate': 0.029836059575621483}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 16:58:01,008] Trial 63 finished with value: 0.19135265069002733 and parameters: {'n_estimators': 314, 'learning_rate': 0.030590585240854867}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 16:58:15,271] Trial 68 finished with value: 0.19132589641520048 and parameters: {'n_estimators': 181, 'learning_rate': 0.0193035673637157}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 17:09:01,596] Trial 70 finished with value: 0.19027045537693685 and parameters: {'n_estimators': 200, 'learning_rate': 0.009676328982510649}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 17:09:40,937] Trial 65 finished with value: 0.1915954179708619 and parameters: {'n_estimators': 319, 'learning_rate': 0.016663245455397803}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 17:10:00,709] Trial 66 finished with value: 0.1907839016893354 and parameters: {'n_estimators': 317, 'learning_rate': 0.007944315465965784}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 17:10:53,553] Trial 71 finished with value: 0.18973150932860616 and parameters: {'n_estimators': 180, 'learning_rate': 0.008251887612414474}. Best is trial 53 with value: 0.19173484739529267.\n",
      "[I 2024-08-24 17:21:03,379] Trial 69 finished with value: 0.19139422915114795 and parameters: {'n_estimators': 334, 'learning_rate': 0.016314147887606375}. Best is trial 53 with value: 0.19173484739529267.\n"
     ]
    }
   ],
   "source": [
    "if ENABLE['ada']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "            \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 400)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 1.0) \n",
    "        \n",
    "        pauc_scores = []\n",
    "\n",
    "        cont = 1\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            print(f'\\rProcessing fold {cont} of {n_splits}...', end='', flush=True)\n",
    "            cont = cont + 1\n",
    "            # Pipeline                                       \n",
    "            pipe_ada = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),\n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "                ('ADA', AdaBoostClassifier(random_state=42,                             \n",
    "                                           n_estimators=n_estimators,\n",
    "                                           learning_rate=learning_rate                             \n",
    "                                          )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_ada.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_ada.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d218132-9ce6-4dce-9400-7b10ae5b0b23",
   "metadata": {},
   "source": [
    "### Cross-validaton Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51159e6-2941-4344-ad66-c8018ffbb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ada = {\n",
    "        'random_state':  42,\n",
    "        'n_estimators':  352,  \n",
    "        'learning_rate': 0.022798770211700257\n",
    "    }\n",
    "\n",
    "model_ada_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('ADA', AdaBoostClassifier(**param_ada))\n",
    "    ])\n",
    "\n",
    "if ENABLE['ada']['compute-pauc'] == 1:\n",
    "    pauc_ada_cv = cross_val_partial_auc_score(X, y, model_ada_cv, n_splits=5)    \n",
    "    print(f\"CV Partial AUC Score: {pauc_ada_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6250aa-9228-4f1b-9450-29070399374a",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30864706-49c5-4f52-a48b-de50008ca947",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['ada']['final-train'] == 1:\n",
    "    \n",
    "    # Pipeline                              \n",
    "    model_ada_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),  \n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "        ('ADA', AdaBoostClassifier(**param_ada)\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model_ada_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e2a8c-a898-464b-9ff6-31cb8ed5cf95",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04044371-b3a8-46bf-b811-baa71b964753",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['ada']['save-model'] == 1:\n",
    "    dump(model_ada_fe139_rsmpl, 'model_ada_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f00ba-7bb8-4df6-bf36-1ec0c8b854e6",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a08ce-78aa-4689-8ae4-840490379e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['svc']['cross-val'] == 1:\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the objective function\n",
    "    def objective(trial):\n",
    "            \n",
    "        # Suggest values for the hyperparameters\n",
    "        random_state = 42\n",
    "        probability = True\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        C = trial.suggest_loguniform('C', 0.0001, 10.0)\n",
    "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        class_weight = trial.suggest_categorical('class_weight', [None, 'balanced']) \n",
    "        \n",
    "        pauc_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            # Create the folds\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                    \n",
    "            # Pipeline\n",
    "            pipe_svc = ImbPipeline([\n",
    "                ('preprocessing', preprocessing),  \n",
    "                ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "                ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "                ('SVC', SVC(random_state=random_state,\n",
    "                            probability=probability,\n",
    "                            kernel=kernel,\n",
    "                            C=C,\n",
    "                            gamma=gamma,\n",
    "                            class_weight=class_weight\n",
    "                           )\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "            # Train the model\n",
    "            pipe_svc.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "            # Predict on the validation set\n",
    "            preds = pipe_svc.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "            # Calculate partical AUC and store it\n",
    "            pauc = partial_auc_score(y_val_fold, preds)\n",
    "            pauc_scores.append(pauc)\n",
    "        \n",
    "        # Return the average\n",
    "        return np.mean(pauc_scores)\n",
    "    \n",
    "    # Create a study object with 'maximize' direction\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Start the optimization\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    \n",
    "    # Get the best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(f'Best trial number: {best_trial.number}')\n",
    "    print(f'Best value (partial auc - 0.8): {best_trial.value}')\n",
    "    print(f'Best hyperparameters: {best_trial.params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c03b5-54f8-45f0-a4bb-bf43851a06a8",
   "metadata": {},
   "source": [
    "### Cross-validation Partial AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a1a00-3c4a-46ea-a65c-80da67fc35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_svc = {\n",
    "        'random_state': 42,\n",
    "        'probability': True,\n",
    "        'kernel': 'linear',\n",
    "        'C': 0.001,\n",
    "        'gamma': 'auto',\n",
    "        'class_weight': balanced\n",
    "}\n",
    "\n",
    "model_svc_cv = ImbPipeline([    \n",
    "        ('preprocessing', preprocessing),\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),\n",
    "        ('ADA', SVC(**param_svc))\n",
    "])\n",
    "\n",
    "if ENABLE['svc']['compute-pauc'] == 1:\n",
    "    pauc_svc_cv = cross_val_partial_auc_score(X, y, model_svc_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_svc_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360753d4-15e8-4539-9dea-f9c8df5f9310",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b82adb-d96e-49ec-8e23-619df656ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['svc']['final-train'] == 1:\n",
    "    \n",
    "    # Pipeline\n",
    "    model_svc_fe139_rsmpl = ImbPipeline([\n",
    "        ('preprocessing', preprocessing),  \n",
    "        ('undersample', RandomUnderSampler(sampling_strategy={0: 40000}, random_state=42)),\n",
    "        ('oversample', SMOTE(sampling_strategy={1: 4000}, random_state=42)),    \n",
    "        ('SVC', SVC(**param_svc)\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model_svc_fe139_rsmpl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd21df1-d7a4-474b-8785-4a24ce9971c2",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269d5af-7d24-4958-a350-3f6ae2060808",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE['svc']['save-model'] == 1:\n",
    "    dump(model_svc_fe139_rsmpl, 'model_svc_fe139_rsmpl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93154a3b-1089-421f-9733-12550f0b535d",
   "metadata": {},
   "source": [
    "# Ensemble: Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b60535-d4fe-4acd-af94-d124cb68921b",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306ef90-19db-4df7-89b3-7d6f70cf2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the soft-voting ensemble archicecture\n",
    "model_soft_cv = VotingClassifier(estimators=[\n",
    "        ('RF',  model_rf_cv),\n",
    "        ('XGB', model_xgb_cv),\n",
    "        ('LGB', model_lgb_cv),\n",
    "        ('CB',  model_cb_cv),\n",
    "        ('ADA', model_ada_cv),\n",
    "        ('SVC', model_svc_cv)\n",
    "], voting='soft')\n",
    "\n",
    "if ENABLE['soft-v']['compute-pauc'] == 1:\n",
    "    pauc_sft_cv = cross_val_partial_auc_score(X, y, model_soft_cv, n_splits=5)\n",
    "    print(f\"CV Partial AUC Score: {pauc_ada_cv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764d40a-5680-4e9c-bb2f-e73be35e30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cross-validation\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "pauc_scores = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "            \n",
    "    # Create the folds\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Create the ensemble model. Assumed these models already pretrained\n",
    "    soft_voting_model = VotingClassifier(estimators=[\n",
    "        ('RF',  model_rf_fe139_rsmpl),\n",
    "        ('XGB', model_xgb_fe139_rsmpl),\n",
    "        ('LGB', model_lgb_fe139_rsmpl),\n",
    "        ('CB',  model_cb_fe139_rsmpl),\n",
    "        ('ADA', model_ada_fe139_rsmpl),\n",
    "        ('SVC', model_svc_fe139_rsmpl),\n",
    "        \n",
    "    # Make predictions with the validation set\n",
    "    #preds1 = model_rf_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds2 = model_xgb_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds3 = model_lgb_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds4 = model_cb_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds5 = model_ada_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "    #preds6 = model_svc_fe139_rsmpl.predict_proba(X_val_fold)[:,1]\n",
    "\n",
    "    #pauc1 = partial_auc_score(y_val_fold, preds1)\n",
    "    #pauc2 = partial_auc_score(y_val_fold, preds2)\n",
    "    #pauc3 = partial_auc_score(y_val_fold, preds3)\n",
    "    #pauc4 = partial_auc_score(y_val_fold, preds4)\n",
    "    #pauc5 = partial_auc_score(y_val_fold, preds5)\n",
    "    #pauc6 = partial_auc_score(y_val_fold, preds6)\n",
    "    \n",
    "    # Combine the partial AUC scores using the average\n",
    "    #pauc_ave = np.mean([preds1, preds2, preds3, preds4, preds5, preds6])\n",
    "\n",
    "    # Predict on the validation set\n",
    "    preds = soft_voting_model.predict_proba(X_val_fold)[:,1]\n",
    "        \n",
    "    # Calculate partical AUC and store it\n",
    "    pauc = partial_auc_score(y_val_fold, preds)\n",
    "    pauc_scores.append(pauc)\n",
    "\n",
    "# Average the scores across all folds\n",
    "average_ensemble_score = np.mean(pauc_scores)\n",
    "print(f'Average partical AUC score - Soft Voting: {average_ensemble_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7f838-7fe0-4605-a795-ec44ba834780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba93eb3-6a65-4c04-8b56-1c3c72fd7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': selected_features,  # This should correspond to your final set of features after KBest\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c1fc0-365a-435d-8b47-cc4fafa872ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0cddc-ddbc-425f-a637-821ab6fd8b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_common",
   "language": "python",
   "name": ".venv_common"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
