{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f52785-438b-40f7-9ac8-2fcd3df4a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "#from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "import tensorflow as tf\n",
    "\n",
    "# From TensorFlow\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, ResNet50V2, EfficientNetB0, EfficientNetB5, EfficientNetB7, DenseNet121, ResNet152V2\n",
    "#from classification_models.tfkeras import Classifiers\n",
    "#ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "#ResNet34, preprocess_input = Classifiers.get('resnet34')\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.models import load_model, Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import AUC, PrecisionAtRecall, SpecificityAtSensitivity, PrecisionAtRecall\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# From scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, recall_score, roc_curve, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61af96-0a18-4379-9110-55a6a8b6bcab",
   "metadata": {},
   "source": [
    "# GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ce28b6-e439-4fff-8170-0412590d970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Check for available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs detected: {gpus}\")\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f4fa7-f20e-490d-9079-e6019e10d242",
   "metadata": {},
   "source": [
    "# Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d5b76a-44a5-43e7-96cc-c117f523fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "IM_SIZE = 128\n",
    "\n",
    "# Read the dataset\n",
    "ROOT_DATASET_DIR = \"../\"\n",
    "DATASET = os.path.join(ROOT_DATASET_DIR,\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc3a45-2d86-43cf-a7f9-823ad7d9a98c",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3863a7-37f8-4e8d-a471-0a7060fa449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting model loss during training, created by Daniel: https://medium.com/geekculture/how-to-plot-model-loss-while-training-in-tensorflow-9fa1a1875a5\n",
    "class plot_learning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "\n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def partial_auc_score_tf(y_true, y_pred):\n",
    "    tpr_threshold = 0.80\n",
    "    max_fpr = 1 - tpr_threshold\n",
    "\n",
    "    # Convert true labels and predictions to float\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    # Calculate the ROC curve with TensorFlow\n",
    "    #fpr, tpr, _ = tf.compat.v1.metrics.auc(y_true, y_pred, curve='ROC')\n",
    "    fpr, tpr, _ = AUC(y_true, y_pred)\n",
    "    #fpr, tpr, _ = tfa.metrics.roc_curve(y_true, y_pred)\n",
    "    \n",
    "    # Find the index where fpr exceeds max_fpr\n",
    "    stop_index = tf.where(fpr <= max_fpr)[-1]\n",
    "\n",
    "    # Gather points up to the stop index\n",
    "    fpr = fpr[:stop_index + 1]\n",
    "    tpr = tpr[:stop_index + 1]\n",
    "\n",
    "    # Add the max_fpr point\n",
    "    fpr = tf.concat([fpr, [max_fpr]], axis=0)\n",
    "    tpr = tf.concat([tpr, [tpr[-1]]], axis=0)\n",
    "\n",
    "    # Calculate the partial AUC\n",
    "    partial_auc_value = tf.reduce_sum(tf.multiply(tf.diff(fpr), (tpr[1:] + tpr[:-1]) / 2))\n",
    "\n",
    "    return partial_auc_value\n",
    "\n",
    "class PartialAUCMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='partial_auc', tpr_threshold=0.80, **kwargs):\n",
    "        super(PartialAUCMetric, self).__init__(name=name, **kwargs)\n",
    "        self.tpr_threshold = tpr_threshold\n",
    "        self.partial_auc = self.add_weight(name='pAUC', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        partial_auc_value = tf.numpy_function(partial_auc_score_tf, [y_true, y_pred, self.tpr_threshold], tf.float32)\n",
    "        self.partial_auc.assign(partial_auc_value)\n",
    "\n",
    "    def result(self):\n",
    "        return self.partial_auc\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.partial_auc.assign(0.0)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Initialize loss functions\n",
    "    bce = BinaryCrossentropy() #(from_logits=True, reduction='none')\n",
    "    sts = SpecificityAtSensitivity(0.8)\n",
    "\n",
    "    # Compute loss functions\n",
    "    loss1 = bce(y_true, y_pred)    \n",
    "    loss2 = sts(y_true, y_pred)\n",
    "\n",
    "    # Ensure consistent data types\n",
    "    loss1 = tf.cast(loss1, tf.float32)\n",
    "    loss2 = tf.cast(loss2, tf.float32)\n",
    "    \n",
    "    loss = -tf.math.log(1 - loss2 + 1e-7) + loss1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b40f8-9bfb-49ee-a261-4ff60f7d566a",
   "metadata": {},
   "source": [
    "# Image Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd8dff23-ed2f-4c6e-b88d-21529c3a9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for custom normalization\n",
    "def custom_normalization(image):\n",
    "    image = image / 255.0\n",
    "    mean = tf.constant(MEAN, dtype=image.dtype)\n",
    "    std = tf.constant(STD, dtype=image.dtype)\n",
    "    image = (image - mean) / std  # Normalize each channel\n",
    "    return image\n",
    "\n",
    "# Function to rotate an image by an angle\n",
    "def rotate_image(image, angle):\n",
    "    radians = angle * (np.pi / 180)  # Convert degrees to radians\n",
    "    return tfa.image.rotate(image, radians)\n",
    "\n",
    "# Image augmentation\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)  # Horizontal flip\n",
    "    image = tf.image.random_flip_up_down(image) # Vertical flip\n",
    "    angle = tf.random.uniform([], minval=-20, maxval=20)\n",
    "    image = rotate_image(image, angle)  # Random rotation\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)  # Random brightness\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)  # Random contrast\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)  # Random saturation\n",
    "    #image = random_zoom(image)  # Random zoom (from additional code)\n",
    "    return image, label\n",
    "\n",
    "# Parse and process images\n",
    "def parse_image(filename, label):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IM_SIZE, IM_SIZE]) #, method=tf.image.ResizeMethod.LANCZOS3)\n",
    "    #image = hair_remove(image)\n",
    "    image = custom_normalization(image)\n",
    "    return image, label\n",
    "\n",
    "# Generate dataset from file paths\n",
    "def generate_dataset(file_paths, labels, batch_size, is_training):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(buffer_size=1000)  # Use a reasonable buffer size\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# List image paths and labels\n",
    "def get_image_paths_and_labels(directory):\n",
    "    data_dir = Path(directory)    \n",
    "    all_image_paths = list(data_dir.glob('*/*.jpg'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]    \n",
    "    all_labels = [0 if '\\\\0' in str(path) else 1 for path in all_image_paths]\n",
    "    return all_image_paths, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c7a50-8bb8-424b-9496-9ebed62d4b99",
   "metadata": {},
   "source": [
    "# Resampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d11eee-bc1f-4ccb-bd0b-d41e5ef0b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to undersample the majority class and oversample the minority class\n",
    "def balance_classes(image_paths, labels, majority_size=None, minority_size=None):\n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Separate the majority and minority classes\n",
    "    majority_class = image_paths[labels == 0]\n",
    "    majority_labels = labels[labels == 0]\n",
    "    \n",
    "    minority_class = image_paths[labels == 1]\n",
    "    minority_labels = labels[labels == 1]\n",
    "    \n",
    "    # Undersample the majority class if majority_size is specified\n",
    "    if majority_size and (majority_size < len(majority_class)):\n",
    "        majority_class_downsampled, majority_labels_downsampled = resample(\n",
    "            majority_class,\n",
    "            majority_labels,\n",
    "            replace=False,  # Sample without replacement\n",
    "            n_samples=majority_size,  # Number of samples after undersampling\n",
    "            random_state=42  # For reproducibility\n",
    "        )\n",
    "    else:\n",
    "        majority_class_downsampled, majority_labels_downsampled = majority_class, majority_labels\n",
    "    \n",
    "    # Oversample the minority class if minority_size is specified\n",
    "    if minority_size and (minority_size > len(minority_class)):\n",
    "        minority_class_upsampled, minority_labels_upsampled = resample(\n",
    "            minority_class,\n",
    "            minority_labels,\n",
    "            replace=True,  # Sample with replacement\n",
    "            n_samples=minority_size,  # Number of samples after oversampling\n",
    "            random_state=42  # For reproducibility\n",
    "        )\n",
    "    else:\n",
    "        minority_class_upsampled, minority_labels_upsampled = minority_class, minority_labels\n",
    "    \n",
    "    # Combine the undersampled majority class and upsampled minority class\n",
    "    balanced_image_paths = np.concatenate([majority_class_downsampled, minority_class_upsampled])\n",
    "    balanced_labels = np.concatenate([majority_labels_downsampled, minority_labels_upsampled])\n",
    "    \n",
    "    return balanced_image_paths.tolist(), balanced_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948eaa0-926e-481b-9bde-438acb86d9f2",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400321d8-3d6a-4483-82ec-0a8216b459a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "all_image_paths, all_labels = get_image_paths_and_labels(DATASET + '/train')\n",
    "\n",
    "# Frequencies of each class\n",
    "n_class_0 = all_labels.count(0)\n",
    "n_class_1 = all_labels.count(1)\n",
    "\n",
    "# Balance the classes by undersampling and oversampling\n",
    "train_paths_balanced, train_labels_balanced = balance_classes(\n",
    "    all_image_paths, \n",
    "    all_labels, \n",
    "    majority_size=n_class_1 * 10,  # Set this to the desired number of majority samples\n",
    "    minority_size=n_class_1 * 10   # Set this to the desired number of minority samples\n",
    ")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_paths, validation_paths, train_labels, validation_labels = train_test_split(\n",
    "    train_paths_balanced, train_labels_balanced, \n",
    "    test_size=0.2, stratify=train_labels_balanced, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = generate_dataset(train_paths, train_labels, BATCH_SIZE, is_training=True)\n",
    "validation_dataset = generate_dataset(validation_paths, validation_labels, BATCH_SIZE, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67f60d-8a4b-4177-87ba-7fa93d886095",
   "metadata": {},
   "source": [
    "# Create CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916fead-dbcc-4f1d-bdbd-db933e3d6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v50'\n",
    "EPOCHS = 50\n",
    "LEARN_RATE = 0.0001\n",
    "REG_RATE = 0.001\n",
    "NEURONS_1 = 256\n",
    "NEURONS_2 = 128\n",
    "NEURONS_3 = 64\n",
    "DROPOUT_RATE = 0.5\n",
    "EVALUATION = 'relu'\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    # Load the pre-trained ResNet50V2 model    \n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "    #base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))\n",
    "\n",
    "    # Freeze the layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Get the output tensor of the base ResNet50V2 model\n",
    "    base_output = base_model.output\n",
    "\n",
    "    # Flatten the output tensor\n",
    "    #x = Flatten()(base_output)\n",
    "    # Use Global Average Pooling\n",
    "    x = GlobalAveragePooling2D()(base_output)    \n",
    "    # Add fully connected layers with dropout\n",
    "    x = Dense(NEURONS_1, kernel_initializer=glorot_uniform(seed=42), activation=EVALUATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "    #x = BatchNormalization()(x)    \n",
    "    x = Dense(NEURONS_2, kernel_initializer=glorot_uniform(seed=42), activation=EVALUATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "    #x = BatchNormalization()(x)    \n",
    "    x = Dense(NEURONS_3, kernel_initializer=glorot_uniform(seed=42), activation=EVALUATION, kernel_regularizer=tf.keras.regularizers.l2(REG_RATE))(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)    \n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile de model\n",
    "optimizer = Adam(learning_rate=LEARN_RATE)\n",
    "eval_metrics = [\"accuracy\", AUC(from_logits=False), SpecificityAtSensitivity(sensitivity=0.8)]\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=eval_metrics)\n",
    "\n",
    "# Checkpoint callbacks\n",
    "best_checkpoint_path = f\"../models/rn152v2_nn{NEURONS_1}_lr{int(LEARN_RATE * 10000):04}_{EVALUATION}_batch{BATCH_SIZE}_epoch{EPOCHS}_{VERSION}_best.keras\"\n",
    "best_checkpoint_callback = ModelCheckpoint(filepath=best_checkpoint_path, save_best_only=True)\n",
    "\n",
    "final_checkpoint_path = f\"../models/rn152v2_nn{NEURONS_1}_lr{int(LEARN_RATE * 10000):04}_{EVALUATION}_batch{BATCH_SIZE}_epoch{EPOCHS}_{VERSION}_final.keras\"\n",
    "final_checkpoint_callback = ModelCheckpoint(filepath=final_checkpoint_path)\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7)\n",
    "\n",
    "print(f\"Best-performing model: {best_checkpoint_path}\")\n",
    "print(f\"Last-epoch model: {final_checkpoint_path}\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,    \n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=validation_dataset,    \n",
    "    callbacks=[plot_learning(), reduce_lr_callback, best_checkpoint_callback, final_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc897d3-75d0-4cec-ad08-6f1a7d2c8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v51'\n",
    "EPOCHS = 50\n",
    "LEARN_RATE = 0.0001\n",
    "REG_RATE = 0.001\n",
    "NEURONS_1 = 256\n",
    "NEURONS_2 = 128\n",
    "NEURONS_3 = 64\n",
    "DROPOUT_RATE = 0.5\n",
    "model = load_model(\"../models/dn121_nn256_lr0001_relu_batch64_epoch50_v50_final.keras\", compile=False)\n",
    "# Compile de model\n",
    "optimizer = Adam(learning_rate=LEARN_RATE)\n",
    "eval_metrics = [\"accuracy\", AUC(from_logits=False), SpecificityAtSensitivity(sensitivity=0.8)]\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=eval_metrics)\n",
    "\n",
    "# Checkpoint callbacks\n",
    "best_checkpoint_path = f\"../models/dn121_nn{NEURONS_1}_lr{int(LEARN_RATE * 10000):04}_relu_batch{BATCH_SIZE}_epoch{EPOCHS*2}_{VERSION}_best.keras\"\n",
    "best_checkpoint_callback = ModelCheckpoint(filepath=best_checkpoint_path, save_best_only=True)\n",
    "\n",
    "final_checkpoint_path = f\"../models/dn121_nn{NEURONS_1}_lr{int(LEARN_RATE * 10000):04}_relu_batch{BATCH_SIZE}_epoch{EPOCHS*2}_{VERSION}_final.keras\"\n",
    "final_checkpoint_callback = ModelCheckpoint(filepath=final_checkpoint_path)\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7)\n",
    "\n",
    "print(f\"Best-performing model: {best_checkpoint_path}\")\n",
    "print(f\"Last-epoch model: {final_checkpoint_path}\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,    \n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=validation_dataset,    \n",
    "    #class_weight=class_weight,\n",
    "    callbacks=[plot_learning(), reduce_lr_callback, best_checkpoint_callback, final_checkpoint_callback] #\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf_gpu (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
